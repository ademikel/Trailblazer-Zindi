{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e93dc6-0157-4ffb-9475-387683327ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries / dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For Modelling\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "\n",
    "# For warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ac5743-bd75-4455-a1b8-30907913c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "ss = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9dfc51-f25a-4bb7-911a-24d0b64d44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7758bba-f280-4dd7-a41f-35007eac08d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ward</th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>target</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_03</th>\n",
       "      <th>pw_04</th>\n",
       "      <th>pw_05</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>pw_07</th>\n",
       "      <th>pw_08</th>\n",
       "      <th>ADM4_PCODE</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41601001: Ward 1</td>\n",
       "      <td>1674.45058</td>\n",
       "      <td>5888.20750</td>\n",
       "      <td>16.773757</td>\n",
       "      <td>0.933841</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ZA4161001</td>\n",
       "      <td>-29.682270</td>\n",
       "      <td>24.734743</td>\n",
       "      <td>0.292039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41601002: Ward 2</td>\n",
       "      <td>1736.99230</td>\n",
       "      <td>6735.33812</td>\n",
       "      <td>21.496661</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.057127</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ZA4161002</td>\n",
       "      <td>-29.119311</td>\n",
       "      <td>24.757737</td>\n",
       "      <td>3.207775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41601003: Ward 3</td>\n",
       "      <td>2403.57591</td>\n",
       "      <td>7273.04995</td>\n",
       "      <td>10.931425</td>\n",
       "      <td>0.810545</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057560</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ZA4161003</td>\n",
       "      <td>-29.142276</td>\n",
       "      <td>25.094093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41601004: Ward 4</td>\n",
       "      <td>1740.78737</td>\n",
       "      <td>5734.49046</td>\n",
       "      <td>23.119257</td>\n",
       "      <td>0.659914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ZA4161004</td>\n",
       "      <td>-29.372052</td>\n",
       "      <td>24.942867</td>\n",
       "      <td>2.038778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41601005: Ward 5</td>\n",
       "      <td>1730.51451</td>\n",
       "      <td>6657.23835</td>\n",
       "      <td>13.652252</td>\n",
       "      <td>0.950575</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ZA4161005</td>\n",
       "      <td>-29.409381</td>\n",
       "      <td>25.290165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ward  total_households  total_individuals     target     dw_00  \\\n",
       "0  41601001: Ward 1        1674.45058         5888.20750  16.773757  0.933841   \n",
       "1  41601002: Ward 2        1736.99230         6735.33812  21.496661  0.696940   \n",
       "2  41601003: Ward 3        2403.57591         7273.04995  10.931425  0.810545   \n",
       "3  41601004: Ward 4        1740.78737         5734.49046  23.119257  0.659914   \n",
       "4  41601005: Ward 5        1730.51451         6657.23835  13.652252  0.950575   \n",
       "\n",
       "      dw_01     dw_02     dw_03     dw_04     dw_05  ...     pw_03     pw_04  \\\n",
       "0  0.000846  0.005490  0.000676  0.000000  0.001372  ...  0.002848  0.007537   \n",
       "1  0.001253  0.004402  0.000000  0.002301  0.001323  ...  0.014566  0.057127   \n",
       "2  0.004517  0.008891  0.003986  0.007735  0.000956  ...  0.057560  0.010358   \n",
       "3  0.000000  0.006129  0.000000  0.000813  0.037245  ...  0.000000  0.000669   \n",
       "4  0.000655  0.001473  0.000598  0.006999  0.000818  ...  0.004859  0.001290   \n",
       "\n",
       "      pw_05     pw_06  pw_07  pw_08  ADM4_PCODE        lat        lon  \\\n",
       "0  0.000000  0.012928      0      0   ZA4161001 -29.682270  24.734743   \n",
       "1  0.019092  0.004131      0      0   ZA4161002 -29.119311  24.757737   \n",
       "2  0.001421  0.040881      0      0   ZA4161003 -29.142276  25.094093   \n",
       "3  0.000000  0.005011      0      0   ZA4161004 -29.372052  24.942867   \n",
       "4  0.000673  0.017629      0      0   ZA4161005 -29.409381  25.290165   \n",
       "\n",
       "         NL  \n",
       "0  0.292039  \n",
       "1  3.207775  \n",
       "2  0.000000  \n",
       "3  2.038778  \n",
       "4  0.000000  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f06272-bd36-4fdc-be0e-2614d37b675d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>dw_07</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_00</th>\n",
       "      <th>pw_01</th>\n",
       "      <th>pw_02</th>\n",
       "      <th>pw_03</th>\n",
       "      <th>pw_04</th>\n",
       "      <th>pw_05</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2504.95194</td>\n",
       "      <td>8745.15151</td>\n",
       "      <td>0.947257</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030116</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551691</td>\n",
       "      <td>0.427445</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>-32.637758</td>\n",
       "      <td>23.848688</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2080.27718</td>\n",
       "      <td>7258.11764</td>\n",
       "      <td>0.844993</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759594</td>\n",
       "      <td>0.227192</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>-31.990536</td>\n",
       "      <td>24.555818</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1106.62639</td>\n",
       "      <td>5919.13170</td>\n",
       "      <td>0.651380</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.259711</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.044153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704033</td>\n",
       "      <td>0.291719</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.283595</td>\n",
       "      <td>24.563940</td>\n",
       "      <td>8.269556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2175.56096</td>\n",
       "      <td>10280.57452</td>\n",
       "      <td>0.410837</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449604</td>\n",
       "      <td>0.009256</td>\n",
       "      <td>0.101963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556172</td>\n",
       "      <td>0.439729</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>-32.261612</td>\n",
       "      <td>24.542202</td>\n",
       "      <td>8.626625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1270.83883</td>\n",
       "      <td>6018.34202</td>\n",
       "      <td>0.942851</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.027930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444380</td>\n",
       "      <td>0.553173</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>-32.251571</td>\n",
       "      <td>24.558537</td>\n",
       "      <td>8.601754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>16076.89903</td>\n",
       "      <td>43296.51372</td>\n",
       "      <td>0.668295</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>0.069741</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992238</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>-33.806524</td>\n",
       "      <td>18.496094</td>\n",
       "      <td>33.913055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>17470.24004</td>\n",
       "      <td>53538.12816</td>\n",
       "      <td>0.483111</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.088044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433723</td>\n",
       "      <td>0.346398</td>\n",
       "      <td>0.158056</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.022417</td>\n",
       "      <td>-33.982120</td>\n",
       "      <td>18.673308</td>\n",
       "      <td>60.009486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>9467.25336</td>\n",
       "      <td>40332.11708</td>\n",
       "      <td>0.579036</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.066458</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.150977</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.099672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733120</td>\n",
       "      <td>0.215139</td>\n",
       "      <td>0.035879</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>-34.062704</td>\n",
       "      <td>18.767457</td>\n",
       "      <td>35.834860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>6111.31195</td>\n",
       "      <td>27793.92916</td>\n",
       "      <td>0.623537</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.101188</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.158979</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.076050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934310</td>\n",
       "      <td>0.022448</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.026741</td>\n",
       "      <td>-34.057772</td>\n",
       "      <td>18.487893</td>\n",
       "      <td>50.153301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>9746.91152</td>\n",
       "      <td>37494.86375</td>\n",
       "      <td>0.689628</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.031751</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.088137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777890</td>\n",
       "      <td>0.099984</td>\n",
       "      <td>0.058847</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>-33.850503</td>\n",
       "      <td>18.721961</td>\n",
       "      <td>43.626138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_households  total_individuals     dw_00     dw_01     dw_02  \\\n",
       "0           2504.95194         8745.15151  0.947257  0.000873  0.002021   \n",
       "1           2080.27718         7258.11764  0.844993  0.000481  0.043629   \n",
       "2           1106.62639         5919.13170  0.651380  0.007937  0.007113   \n",
       "3           2175.56096        10280.57452  0.410837  0.002468  0.011511   \n",
       "4           1270.83883         6018.34202  0.942851  0.002638  0.000821   \n",
       "...                ...                ...       ...       ...       ...   \n",
       "1008       16076.89903        43296.51372  0.668295  0.002827  0.207749   \n",
       "1009       17470.24004        53538.12816  0.483111  0.000824  0.001189   \n",
       "1010        9467.25336        40332.11708  0.579036  0.007184  0.066458   \n",
       "1011        6111.31195        27793.92916  0.623537  0.002216  0.101188   \n",
       "1012        9746.91152        37494.86375  0.689628  0.002557  0.010899   \n",
       "\n",
       "         dw_03     dw_04     dw_05     dw_06     dw_07  ...     pw_00  \\\n",
       "0     0.000000  0.000000  0.030116  0.000452  0.013018  ...  0.551691   \n",
       "1     0.004714  0.012323  0.012300  0.022132  0.022412  ...  0.759594   \n",
       "2     0.000000  0.001977  0.259711  0.006505  0.044153  ...  0.704033   \n",
       "3     0.000485  0.000000  0.449604  0.009256  0.101963  ...  0.556172   \n",
       "4     0.000000  0.000891  0.000787  0.000830  0.027930  ...  0.444380   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "1008  0.028813  0.069741  0.010701  0.003941  0.000804  ...  0.992238   \n",
       "1009  0.000870  0.000554  0.000370  0.001954  0.088044  ...  0.433723   \n",
       "1010  0.001003  0.000371  0.150977  0.007699  0.099672  ...  0.733120   \n",
       "1011  0.001517  0.000939  0.158979  0.013516  0.076050  ...  0.934310   \n",
       "1012  0.001380  0.001674  0.031751  0.008765  0.088137  ...  0.777890   \n",
       "\n",
       "         pw_01     pw_02     pw_03     pw_04     pw_05     pw_06        lat  \\\n",
       "0     0.427445  0.012457  0.001757  0.000000  0.000000  0.006649 -32.637758   \n",
       "1     0.227192  0.009606  0.000691  0.000000  0.000000  0.002916 -31.990536   \n",
       "2     0.291719  0.001996  0.002253  0.000000  0.000000  0.000000 -32.283595   \n",
       "3     0.439729  0.002060  0.000000  0.000661  0.000000  0.001379 -32.261612   \n",
       "4     0.553173  0.000787  0.000000  0.000000  0.000000  0.001660 -32.251571   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "1008  0.004045  0.000609  0.000392  0.000291  0.000148  0.002277 -33.806524   \n",
       "1009  0.346398  0.158056  0.030744  0.008313  0.000348  0.022417 -33.982120   \n",
       "1010  0.215139  0.035879  0.003850  0.000990  0.000352  0.010670 -34.062704   \n",
       "1011  0.022448  0.015737  0.000559  0.000000  0.000204  0.026741 -34.057772   \n",
       "1012  0.099984  0.058847  0.047527  0.000783  0.004717  0.010252 -33.850503   \n",
       "\n",
       "            lon         NL  \n",
       "0     23.848688   0.000000  \n",
       "1     24.555818   0.000000  \n",
       "2     24.563940   8.269556  \n",
       "3     24.542202   8.626625  \n",
       "4     24.558537   8.601754  \n",
       "...         ...        ...  \n",
       "1008  18.496094  33.913055  \n",
       "1009  18.673308  60.009486  \n",
       "1010  18.767457  35.834860  \n",
       "1011  18.487893  50.153301  \n",
       "1012  18.721961  43.626138  \n",
       "\n",
       "[1013 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_cols(dataset, col):\n",
    "    for data in dataset:\n",
    "        data.drop(col, axis = 1, inplace = True)\n",
    "    return data\n",
    "col = ['dw_12', 'dw_13', 'lan_13', 'pw_07', 'pw_08', 'ward', 'ADM4_PCODE']\n",
    "drop_cols(datasets, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3ab390-5540-4571-9bec-85b8d4e34836",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>dw_07</th>\n",
       "      <th>dw_08</th>\n",
       "      <th>dw_09</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>ind_per_house</th>\n",
       "      <th>dw</th>\n",
       "      <th>lan</th>\n",
       "      <th>pw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947257</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030116</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>-32.637758</td>\n",
       "      <td>23.848688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.701130</td>\n",
       "      <td>1.557033</td>\n",
       "      <td>3.491145</td>\n",
       "      <td>0.980268</td>\n",
       "      <td>0.967260</td>\n",
       "      <td>0.993351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.844993</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>-31.990536</td>\n",
       "      <td>24.555818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.922068</td>\n",
       "      <td>2.040153</td>\n",
       "      <td>3.489015</td>\n",
       "      <td>0.918440</td>\n",
       "      <td>0.833398</td>\n",
       "      <td>0.997084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.651380</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.259711</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.044153</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.283595</td>\n",
       "      <td>24.563940</td>\n",
       "      <td>8.269556</td>\n",
       "      <td>2.778162</td>\n",
       "      <td>1.688474</td>\n",
       "      <td>5.348808</td>\n",
       "      <td>0.928118</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.410837</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449604</td>\n",
       "      <td>0.009256</td>\n",
       "      <td>0.101963</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>-32.261612</td>\n",
       "      <td>24.542202</td>\n",
       "      <td>8.626625</td>\n",
       "      <td>2.325306</td>\n",
       "      <td>1.579226</td>\n",
       "      <td>4.725482</td>\n",
       "      <td>0.874905</td>\n",
       "      <td>0.892816</td>\n",
       "      <td>0.998621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.942851</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.027930</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.017343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>-32.251571</td>\n",
       "      <td>24.558537</td>\n",
       "      <td>8.601754</td>\n",
       "      <td>2.709457</td>\n",
       "      <td>1.398725</td>\n",
       "      <td>4.735724</td>\n",
       "      <td>0.947989</td>\n",
       "      <td>0.989536</td>\n",
       "      <td>0.998340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0.668295</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>0.069741</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>-33.806524</td>\n",
       "      <td>18.496094</td>\n",
       "      <td>33.913055</td>\n",
       "      <td>1.133560</td>\n",
       "      <td>2.610884</td>\n",
       "      <td>2.693089</td>\n",
       "      <td>0.988126</td>\n",
       "      <td>0.874785</td>\n",
       "      <td>0.997575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>0.483111</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.088044</td>\n",
       "      <td>0.416686</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022417</td>\n",
       "      <td>-33.982120</td>\n",
       "      <td>18.673308</td>\n",
       "      <td>60.009486</td>\n",
       "      <td>3.020161</td>\n",
       "      <td>1.281801</td>\n",
       "      <td>3.064533</td>\n",
       "      <td>0.486918</td>\n",
       "      <td>0.937696</td>\n",
       "      <td>0.977234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.579036</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.066458</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.150977</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.099672</td>\n",
       "      <td>0.070348</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>-34.062704</td>\n",
       "      <td>18.767457</td>\n",
       "      <td>35.834860</td>\n",
       "      <td>2.576032</td>\n",
       "      <td>1.708089</td>\n",
       "      <td>4.260171</td>\n",
       "      <td>0.805030</td>\n",
       "      <td>0.972096</td>\n",
       "      <td>0.988978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.623537</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.101188</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.158979</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.076050</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.014067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026741</td>\n",
       "      <td>-34.057772</td>\n",
       "      <td>18.487893</td>\n",
       "      <td>50.153301</td>\n",
       "      <td>1.861088</td>\n",
       "      <td>1.929308</td>\n",
       "      <td>4.547948</td>\n",
       "      <td>0.888378</td>\n",
       "      <td>0.975218</td>\n",
       "      <td>0.973054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>0.689628</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.031751</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.088137</td>\n",
       "      <td>0.150055</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>-33.850503</td>\n",
       "      <td>18.721961</td>\n",
       "      <td>43.626138</td>\n",
       "      <td>2.500364</td>\n",
       "      <td>1.731189</td>\n",
       "      <td>3.846846</td>\n",
       "      <td>0.737889</td>\n",
       "      <td>0.915933</td>\n",
       "      <td>0.985031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dw_00     dw_01     dw_02     dw_03     dw_04     dw_05     dw_06  \\\n",
       "0     0.947257  0.000873  0.002021  0.000000  0.000000  0.030116  0.000452   \n",
       "1     0.844993  0.000481  0.043629  0.004714  0.012323  0.012300  0.022132   \n",
       "2     0.651380  0.007937  0.007113  0.000000  0.001977  0.259711  0.006505   \n",
       "3     0.410837  0.002468  0.011511  0.000485  0.000000  0.449604  0.009256   \n",
       "4     0.942851  0.002638  0.000821  0.000000  0.000891  0.000787  0.000830   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1008  0.668295  0.002827  0.207749  0.028813  0.069741  0.010701  0.003941   \n",
       "1009  0.483111  0.000824  0.001189  0.000870  0.000554  0.000370  0.001954   \n",
       "1010  0.579036  0.007184  0.066458  0.001003  0.000371  0.150977  0.007699   \n",
       "1011  0.623537  0.002216  0.101188  0.001517  0.000939  0.158979  0.013516   \n",
       "1012  0.689628  0.002557  0.010899  0.001380  0.001674  0.031751  0.008765   \n",
       "\n",
       "         dw_07     dw_08     dw_09  ...     pw_06        lat        lon  \\\n",
       "0     0.013018  0.003516  0.000000  ...  0.006649 -32.637758  23.848688   \n",
       "1     0.022412  0.016969  0.006702  ...  0.002916 -31.990536  24.555818   \n",
       "2     0.044153  0.013530  0.000000  ...  0.000000 -32.283595  24.563940   \n",
       "3     0.101963  0.001516  0.009203  ...  0.001379 -32.261612  24.542202   \n",
       "4     0.027930  0.001617  0.017343  ...  0.001660 -32.251571  24.558537   \n",
       "...        ...       ...       ...  ...       ...        ...        ...   \n",
       "1008  0.000804  0.002530  0.003673  ...  0.002277 -33.806524  18.496094   \n",
       "1009  0.088044  0.416686  0.000066  ...  0.022417 -33.982120  18.673308   \n",
       "1010  0.099672  0.070348  0.006363  ...  0.010670 -34.062704  18.767457   \n",
       "1011  0.076050  0.001687  0.014067  ...  0.026741 -34.057772  18.487893   \n",
       "1012  0.088137  0.150055  0.006373  ...  0.010252 -33.850503  18.721961   \n",
       "\n",
       "             NL        f1        f2  ind_per_house        dw       lan  \\\n",
       "0      0.000000  2.701130  1.557033       3.491145  0.980268  0.967260   \n",
       "1      0.000000  1.922068  2.040153       3.489015  0.918440  0.833398   \n",
       "2      8.269556  2.778162  1.688474       5.348808  0.928118  0.987500   \n",
       "3      8.626625  2.325306  1.579226       4.725482  0.874905  0.892816   \n",
       "4      8.601754  2.709457  1.398725       4.735724  0.947989  0.989536   \n",
       "...         ...       ...       ...            ...       ...       ...   \n",
       "1008  33.913055  1.133560  2.610884       2.693089  0.988126  0.874785   \n",
       "1009  60.009486  3.020161  1.281801       3.064533  0.486918  0.937696   \n",
       "1010  35.834860  2.576032  1.708089       4.260171  0.805030  0.972096   \n",
       "1011  50.153301  1.861088  1.929308       4.547948  0.888378  0.975218   \n",
       "1012  43.626138  2.500364  1.731189       3.846846  0.737889  0.915933   \n",
       "\n",
       "            pw  \n",
       "0     0.993351  \n",
       "1     0.997084  \n",
       "2     1.000000  \n",
       "3     0.998621  \n",
       "4     0.998340  \n",
       "...        ...  \n",
       "1008  0.997575  \n",
       "1009  0.977234  \n",
       "1010  0.988978  \n",
       "1011  0.973054  \n",
       "1012  0.985031  \n",
       "\n",
       "[1013 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def features(dataset):\n",
    "    for data in dataset:\n",
    "        data['f1'] = data.psa_00 + data.car_01 + data.stv_01 + data.lln_01\n",
    "        data['f2'] = data.lgt_00 + data.pw_00 + data.pg_03 + data.dw_01\n",
    "        data['ind_per_house'] = data.total_individuals / data.total_households\n",
    "        data['dw'] = data.dw_00 + data.dw_01 + data.dw_02 + data.dw_03 + data.dw_04 + data.dw_05\n",
    "        data['lan'] = data.lan_00 + data.lan_01 + data.lan_02 + data.lan_03 + data.lan_04 + data.lan_05\n",
    "        data['pw'] = data.pw_00 + data.pw_01 + data.pw_02 + data.pw_03 + data.pw_04\n",
    "        data.drop(['total_individuals', 'total_households'], axis = 1, inplace = True)\n",
    "    return data\n",
    "features(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b006bce-c206-4ba2-91f1-891e825b2243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['psa_00', 'f1', 'car_01', 'stv_01', 'lln_01', 'pg_00', 'pw_06', 'dw_01',\n",
       "       'pw_02', 'pw_03', 'pw_04', 'pw_05', 'lon', 'dw', 'lan_05', 'lan_04',\n",
       "       'lan_11', 'psa_04', 'lat', 'pw_01', 'lan_10', 'lan_09', 'dw_00',\n",
       "       'lan_08', 'lan_02', 'lan_06', 'ind_per_house', 'lan', 'lan_07',\n",
       "       'psa_02', 'dw_11', 'dw_10', 'lan_03', 'dw_05', 'dw_07', 'dw_08',\n",
       "       'pg_04', 'pg_02', 'dw_02', 'pg_01', 'dw_09', 'dw_06', 'lgt_00',\n",
       "       'lan_14', 'psa_03', 'lan_12', 'dw_03', 'dw_04', 'lan_01', 'pw',\n",
       "       'lan_00', 'NL', 'pg_03', 'lln_00', 'f2', 'stv_00', 'car_00', 'psa_01',\n",
       "       'pw_00'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = {}\n",
    "cols = train.columns.difference(['target'])\n",
    "for col in cols:\n",
    "    keep[col] = train.target.corr(train[col])\n",
    "pd.Series(keep).sort_values(ascending = False).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021a3ae0-2856-4dff-a099-859ff030c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = ['psa_00', 'f1', 'car_01', 'stv_01', 'lln_01', 'pg_00', 'pw_06', 'dw_01',\n",
    "       'pw_02', 'pw_03', 'pw_04', 'pw_05', 'lon', 'dw', 'lan_05', 'lan_04',\n",
    "       'lan_11', 'psa_04', 'lat', 'pw_01', 'lan_10', 'lan_09', 'dw_00',\n",
    "       'lan_08', 'lan_02', 'lan_06', 'ind_per_house', 'lan', 'lan_07',\n",
    "       'psa_02', 'dw_11', 'dw_10', 'lan_03', 'dw_05', 'dw_07', 'dw_08',\n",
    "       'pg_04', 'pg_02', 'dw_02', 'pg_01', 'dw_09', 'dw_06', 'lgt_00',\n",
    "       'lan_14', 'psa_03', 'lan_12', 'dw_03', 'dw_04', 'lan_01', 'pw',\n",
    "       'lan_00', 'NL', 'pg_03', 'lln_00', 'f2', 'stv_00', 'car_00', 'psa_01',\n",
    "       'pw_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d933d5-4b78-4d6f-82e6-7adc6358327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X = train[main]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54012404-2868-42ff-8653-ecf539867ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = train.drop('target', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44915b86-f9e2-4a0c-9570-f27ff6c3fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "debb6948-ebea-49b3-9ad3-d07cf0a1e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7148b-ff1d-4cb4-a0dd-59ca31af9684",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67154a6d-8d97-44d4-850f-5e5610739b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.887011450204307"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cat_ = CatBoostRegressor(verbose = 0, n_estimators = 2000) # Create the model\n",
    "model_cat_.fit(X_train, y_train) # Train it (this syntax looks the same for all sklearn models)\n",
    "y_test_cat = model_cat_.predict(X_test)\n",
    "error_test_cat = mean_squared_error(y_test, y_test_cat, squared = False)\n",
    "error_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62e39c8e-f03c-4d5a-bd10-c86f3c30c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9061375764198"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ = CatBoostRegressor(verbose = 0, n_estimators = 2000) # Create the model\n",
    "cat_.fit(X_train_, y_train_) # Train it (this syntax looks the same for all sklearn models)\n",
    "y_test_cat = cat_.predict(X_test_)\n",
    "error_test_cat = mean_squared_error(y_test_, y_test_cat, squared = False)\n",
    "error_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a987380-097a-472a-b37e-51660defc2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.8840898961840318\n",
      "RMSE: 3.1886095385404767\n",
      "RMSE: 3.242673833877179\n",
      "RMSE: 3.0998352957052644\n",
      "RMSE: 3.085620200872677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1001657530359257"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "score = []\n",
    "for train_index, test_index in fold.split(X):\n",
    "    x_train_, x_test_ = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_, y_test_ = y.iloc[train_index], y.iloc[test_index]\n",
    "    cat = CatBoostRegressor(n_estimators = 2000, verbose = 0, iterations = 955, max_depth = 6, subsample = 0.6382849390832925, \n",
    "                               learning_rate = 0.058582676139219296, min_child_samples = 38, l2_leaf_reg = 2)\n",
    "    cat.fit(x_train_, y_train_) # Train it (this syntax looks the same for all sklearn models)\n",
    "    y_hat = cat.predict(x_test_)\n",
    "    error = mean_squared_error(y_test_, y_hat, squared = False)\n",
    "    print(f'RMSE: {error}')\n",
    "    score.append(error)\n",
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f10b7646-3529-4e31-a382-5bba2160536e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 18:10:01,295]\u001b[0m A new study created in memory with name: no-name-22b0fbc2-47e1-4707-8050-5b604f5275ec\u001b[0m\n",
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe.\u001b[32m[I 2022-04-19 18:10:09,425]\u001b[0m Trial 0 finished with value: 3.007776688941753 and parameters: {'model__iterations': 586, 'model__max_depth': 5, 'model__subsample': 0.7730848936264454, 'model__learning_rate': 0.08486564055473661, 'model__min_child_samples': 48, 'model__l2_leaf_reg': 0}. Best is trial 0 with value: 3.007776688941753.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:10:50,673]\u001b[0m Trial 1 finished with value: 2.9759998304228645 and parameters: {'model__iterations': 710, 'model__max_depth': 8, 'model__subsample': 0.6181337169178127, 'model__learning_rate': 0.05580308482380891, 'model__min_child_samples': 48, 'model__l2_leaf_reg': 4}. Best is trial 1 with value: 2.9759998304228645.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:11:11,080]\u001b[0m Trial 2 finished with value: 2.9613368201069177 and parameters: {'model__iterations': 496, 'model__max_depth': 7, 'model__subsample': 0.680275352413389, 'model__learning_rate': 0.07607005636183212, 'model__min_child_samples': 36, 'model__l2_leaf_reg': 4}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:11:17,431]\u001b[0m Trial 3 finished with value: 3.1779756925138787 and parameters: {'model__iterations': 438, 'model__max_depth': 3, 'model__subsample': 0.8019451464666949, 'model__learning_rate': 0.043784582463551776, 'model__min_child_samples': 44, 'model__l2_leaf_reg': 1}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:12:05,967]\u001b[0m Trial 4 finished with value: 2.977955489202357 and parameters: {'model__iterations': 689, 'model__max_depth': 8, 'model__subsample': 0.6069338187704968, 'model__learning_rate': 0.08979137036934416, 'model__min_child_samples': 44, 'model__l2_leaf_reg': 3}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:13:12,221]\u001b[0m Trial 5 finished with value: 3.066421131035859 and parameters: {'model__iterations': 400, 'model__max_depth': 9, 'model__subsample': 0.9267954651791226, 'model__learning_rate': 0.055123095197997254, 'model__min_child_samples': 46, 'model__l2_leaf_reg': 3}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:13:29,085]\u001b[0m Trial 6 finished with value: 2.9901474224061824 and parameters: {'model__iterations': 543, 'model__max_depth': 6, 'model__subsample': 0.8604702029441577, 'model__learning_rate': 0.07182431133823539, 'model__min_child_samples': 39, 'model__l2_leaf_reg': 4}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:13:37,045]\u001b[0m Trial 7 finished with value: 3.024931438376374 and parameters: {'model__iterations': 775, 'model__max_depth': 4, 'model__subsample': 0.8566531912869685, 'model__learning_rate': 0.053368076805588124, 'model__min_child_samples': 31, 'model__l2_leaf_reg': 0}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:18:36,490]\u001b[0m Trial 8 finished with value: 3.215261596267703 and parameters: {'model__iterations': 775, 'model__max_depth': 10, 'model__subsample': 0.8132874237611556, 'model__learning_rate': 0.07308399920363837, 'model__min_child_samples': 49, 'model__l2_leaf_reg': 0}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:20:06,081]\u001b[0m Trial 9 finished with value: 3.0535333156254874 and parameters: {'model__iterations': 648, 'model__max_depth': 9, 'model__subsample': 0.7782882427341798, 'model__learning_rate': 0.08584547368615286, 'model__min_child_samples': 30, 'model__l2_leaf_reg': 3}. Best is trial 2 with value: 2.9613368201069177.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:20:44,777]\u001b[0m Trial 10 finished with value: 2.915002176556153 and parameters: {'model__iterations': 897, 'model__max_depth': 7, 'model__subsample': 0.6939192980379352, 'model__learning_rate': 0.039188788185895045, 'model__min_child_samples': 37, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:21:31,520]\u001b[0m Trial 11 finished with value: 2.971867332797798 and parameters: {'model__iterations': 990, 'model__max_depth': 7, 'model__subsample': 0.7002154394899559, 'model__learning_rate': 0.03239306720747702, 'model__min_child_samples': 36, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:21:55,984]\u001b[0m Trial 12 finished with value: 2.9643306618335146 and parameters: {'model__iterations': 923, 'model__max_depth': 6, 'model__subsample': 0.6918608685298041, 'model__learning_rate': 0.035230545400779925, 'model__min_child_samples': 36, 'model__l2_leaf_reg': 2}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:22:38,100]\u001b[0m Trial 13 finished with value: 2.924256259218612 and parameters: {'model__iterations': 871, 'model__max_depth': 7, 'model__subsample': 0.6906739686390809, 'model__learning_rate': 0.06770718412411618, 'model__min_child_samples': 35, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:22:53,704]\u001b[0m Trial 14 finished with value: 2.983101151823572 and parameters: {'model__iterations': 864, 'model__max_depth': 5, 'model__subsample': 0.7270665657497382, 'model__learning_rate': 0.06437048826472411, 'model__min_child_samples': 40, 'model__l2_leaf_reg': 2}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:23:58,684]\u001b[0m Trial 15 finished with value: 2.9753880958641075 and parameters: {'model__iterations': 855, 'model__max_depth': 8, 'model__subsample': 0.9970298874470147, 'model__learning_rate': 0.048111603505457234, 'model__min_child_samples': 34, 'model__l2_leaf_reg': 3}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:24:39,430]\u001b[0m Trial 16 finished with value: 2.9156647263374498 and parameters: {'model__iterations': 994, 'model__max_depth': 7, 'model__subsample': 0.6398274050262012, 'model__learning_rate': 0.062227922325136076, 'model__min_child_samples': 33, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:24:54,891]\u001b[0m Trial 17 finished with value: 2.9719610733697244 and parameters: {'model__iterations': 1000, 'model__max_depth': 5, 'model__subsample': 0.6475624681202499, 'model__learning_rate': 0.04161296585756802, 'model__min_child_samples': 33, 'model__l2_leaf_reg': 1}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:25:20,723]\u001b[0m Trial 18 finished with value: 2.956199448022421 and parameters: {'model__iterations': 930, 'model__max_depth': 6, 'model__subsample': 0.7294441270874654, 'model__learning_rate': 0.09591098878104282, 'model__min_child_samples': 39, 'model__l2_leaf_reg': 3}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:27:08,987]\u001b[0m Trial 19 finished with value: 3.0075722637347875 and parameters: {'model__iterations': 791, 'model__max_depth': 9, 'model__subsample': 0.6423683820943465, 'model__learning_rate': 0.06165471012734626, 'model__min_child_samples': 41, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:33:09,944]\u001b[0m Trial 20 finished with value: 3.046068210957624 and parameters: {'model__iterations': 935, 'model__max_depth': 10, 'model__subsample': 0.7385576373878378, 'model__learning_rate': 0.03917697462608294, 'model__min_child_samples': 32, 'model__l2_leaf_reg': 2}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:33:47,174]\u001b[0m Trial 21 finished with value: 2.9443147608201814 and parameters: {'model__iterations': 863, 'model__max_depth': 7, 'model__subsample': 0.6576532446071185, 'model__learning_rate': 0.06877343312579343, 'model__min_child_samples': 34, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:34:28,546]\u001b[0m Trial 22 finished with value: 2.981506502857952 and parameters: {'model__iterations': 901, 'model__max_depth': 7, 'model__subsample': 0.6051760134691573, 'model__learning_rate': 0.08123002405592473, 'model__min_child_samples': 37, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:35:44,836]\u001b[0m Trial 23 finished with value: 3.0115863977934247 and parameters: {'model__iterations': 813, 'model__max_depth': 8, 'model__subsample': 0.6686592711141625, 'model__learning_rate': 0.06281158815934862, 'model__min_child_samples': 38, 'model__l2_leaf_reg': 3}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:36:13,220]\u001b[0m Trial 24 finished with value: 2.939422450076952 and parameters: {'model__iterations': 965, 'model__max_depth': 6, 'model__subsample': 0.7135107141286374, 'model__learning_rate': 0.05051396169741266, 'model__min_child_samples': 34, 'model__l2_leaf_reg': 4}. Best is trial 10 with value: 2.915002176556153.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:36:52,388]\u001b[0m Trial 25 finished with value: 2.8911250881626693 and parameters: {'model__iterations': 884, 'model__max_depth': 7, 'model__subsample': 0.7550054701375982, 'model__learning_rate': 0.059786272064264005, 'model__min_child_samples': 42, 'model__l2_leaf_reg': 3}. Best is trial 25 with value: 2.8911250881626693.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:38:05,901]\u001b[0m Trial 26 finished with value: 2.977676281917536 and parameters: {'model__iterations': 822, 'model__max_depth': 8, 'model__subsample': 0.7582334623377529, 'model__learning_rate': 0.06014132012091535, 'model__min_child_samples': 42, 'model__l2_leaf_reg': 3}. Best is trial 25 with value: 2.8911250881626693.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:38:19,263]\u001b[0m Trial 27 finished with value: 2.9987688743677356 and parameters: {'model__iterations': 729, 'model__max_depth': 5, 'model__subsample': 0.8256286788105335, 'model__learning_rate': 0.04439210862167464, 'model__min_child_samples': 43, 'model__l2_leaf_reg': 3}. Best is trial 25 with value: 2.8911250881626693.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:38:43,054]\u001b[0m Trial 28 finished with value: 2.923584001096474 and parameters: {'model__iterations': 956, 'model__max_depth': 6, 'model__subsample': 0.6318657755598507, 'model__learning_rate': 0.05800489153928164, 'model__min_child_samples': 38, 'model__l2_leaf_reg': 2}. Best is trial 25 with value: 2.8911250881626693.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:38:52,314]\u001b[0m Trial 29 finished with value: 3.011741760201583 and parameters: {'model__iterations': 895, 'model__max_depth': 4, 'model__subsample': 0.7709893401805701, 'model__learning_rate': 0.0480540753641981, 'model__min_child_samples': 46, 'model__l2_leaf_reg': 3}. Best is trial 25 with value: 2.8911250881626693.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:39:17,103]\u001b[0m Trial 30 finished with value: 2.985292734783552 and parameters: {'model__iterations': 596, 'model__max_depth': 7, 'model__subsample': 0.7646952910546843, 'model__learning_rate': 0.07847754786269792, 'model__min_child_samples': 32, 'model__l2_leaf_reg': 1}. Best is trial 25 with value: 2.8911250881626693.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:39:43,602]\u001b[0m Trial 31 finished with value: 2.8874193509552564 and parameters: {'model__iterations': 955, 'model__max_depth': 6, 'model__subsample': 0.6382849390832925, 'model__learning_rate': 0.058582676139219296, 'model__min_child_samples': 38, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:40:08,461]\u001b[0m Trial 32 finished with value: 2.889746041186566 and parameters: {'model__iterations': 962, 'model__max_depth': 6, 'model__subsample': 0.626029270304891, 'model__learning_rate': 0.05263920266304334, 'model__min_child_samples': 40, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:40:33,988]\u001b[0m Trial 33 finished with value: 2.899397761532834 and parameters: {'model__iterations': 955, 'model__max_depth': 6, 'model__subsample': 0.6708189229438393, 'model__learning_rate': 0.03634036992158153, 'model__min_child_samples': 40, 'model__l2_leaf_reg': 1}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:40:44,834]\u001b[0m Trial 34 finished with value: 2.9709900745527325 and parameters: {'model__iterations': 960, 'model__max_depth': 4, 'model__subsample': 0.6220008541273626, 'model__learning_rate': 0.05232344168319105, 'model__min_child_samples': 41, 'model__l2_leaf_reg': 1}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:41:00,647]\u001b[0m Trial 35 finished with value: 2.9252629752589616 and parameters: {'model__iterations': 956, 'model__max_depth': 5, 'model__subsample': 0.6585476961914001, 'model__learning_rate': 0.05719614714486937, 'model__min_child_samples': 42, 'model__l2_leaf_reg': 1}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:41:23,411]\u001b[0m Trial 36 finished with value: 2.911543820854095 and parameters: {'model__iterations': 925, 'model__max_depth': 6, 'model__subsample': 0.6026785011552297, 'model__learning_rate': 0.03162952129129507, 'model__min_child_samples': 44, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:41:43,126]\u001b[0m Trial 37 finished with value: 2.9592953266552677 and parameters: {'model__iterations': 830, 'model__max_depth': 6, 'model__subsample': 0.6737132078513155, 'model__learning_rate': 0.0458718288258472, 'model__min_child_samples': 40, 'model__l2_leaf_reg': 1}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:41:53,983]\u001b[0m Trial 38 finished with value: 2.9862016292251687 and parameters: {'model__iterations': 730, 'model__max_depth': 5, 'model__subsample': 0.616942452769303, 'model__learning_rate': 0.06726585278858649, 'model__min_child_samples': 45, 'model__l2_leaf_reg': 0}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:42:04,265]\u001b[0m Trial 39 finished with value: 2.9821089338874622 and parameters: {'model__iterations': 897, 'model__max_depth': 4, 'model__subsample': 0.7439681449822241, 'model__learning_rate': 0.056334951948568766, 'model__min_child_samples': 40, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:42:10,100]\u001b[0m Trial 40 finished with value: 3.1944485423629416 and parameters: {'model__iterations': 472, 'model__max_depth': 3, 'model__subsample': 0.8464749115074917, 'model__learning_rate': 0.0361013621770095, 'model__min_child_samples': 47, 'model__l2_leaf_reg': 1}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:42:32,203]\u001b[0m Trial 41 finished with value: 2.949699254269703 and parameters: {'model__iterations': 925, 'model__max_depth': 6, 'model__subsample': 0.6095804833342398, 'model__learning_rate': 0.03185141361617916, 'model__min_child_samples': 44, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:42:56,628]\u001b[0m Trial 42 finished with value: 2.943450451400112 and parameters: {'model__iterations': 975, 'model__max_depth': 6, 'model__subsample': 0.601563543364699, 'model__learning_rate': 0.036264631878070094, 'model__min_child_samples': 43, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:43:17,126]\u001b[0m Trial 43 finished with value: 2.9244827678061167 and parameters: {'model__iterations': 938, 'model__max_depth': 6, 'model__subsample': 0.6289987851612548, 'model__learning_rate': 0.0411099812808176, 'model__min_child_samples': 50, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:43:30,920]\u001b[0m Trial 44 finished with value: 3.0211981733232833 and parameters: {'model__iterations': 904, 'model__max_depth': 5, 'model__subsample': 0.884698943397873, 'model__learning_rate': 0.03014380109163819, 'model__min_child_samples': 42, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:43:47,460]\u001b[0m Trial 45 finished with value: 2.972498099435955 and parameters: {'model__iterations': 663, 'model__max_depth': 6, 'model__subsample': 0.7925862991565777, 'model__learning_rate': 0.07289217456060487, 'model__min_child_samples': 39, 'model__l2_leaf_reg': 1}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:44:22,912]\u001b[0m Trial 46 finished with value: 2.9769776798237024 and parameters: {'model__iterations': 842, 'model__max_depth': 7, 'model__subsample': 0.678638209053744, 'model__learning_rate': 0.05292514907404955, 'model__min_child_samples': 45, 'model__l2_leaf_reg': 0}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:44:57,128]\u001b[0m Trial 47 finished with value: 2.947899675687938 and parameters: {'model__iterations': 976, 'model__max_depth': 7, 'model__subsample': 0.7069120536318187, 'model__learning_rate': 0.048985651720306556, 'model__min_child_samples': 41, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:46:02,426]\u001b[0m Trial 48 finished with value: 2.98817400559223 and parameters: {'model__iterations': 887, 'model__max_depth': 8, 'model__subsample': 0.6510329204145824, 'model__learning_rate': 0.03407189941711515, 'model__min_child_samples': 38, 'model__l2_leaf_reg': 1}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n",
      "\u001b[32m[I 2022-04-19 18:46:24,668]\u001b[0m Trial 49 finished with value: 2.9605843116471187 and parameters: {'model__iterations': 916, 'model__max_depth': 6, 'model__subsample': 0.6264748954083229, 'model__learning_rate': 0.03901659319587382, 'model__min_child_samples': 43, 'model__l2_leaf_reg': 2}. Best is trial 31 with value: 2.8874193509552564.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    model = CatBoostRegressor(\n",
    "        iterations = trial.suggest_int('iterations', 400, 1000),\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 10),\n",
    "        subsample = trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.03, 0.1),\n",
    "        min_child_samples = trial.suggest_int('min_child_samples', 30, 50),\n",
    "        l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 0.2, 5),\n",
    "        logging_level = 'Silent',\n",
    "        od_type = 'iter',\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose = 0, early_stopping_rounds = 200)\n",
    "    cat = CatBoostRegressor(n_estimators = 2000, verbose = 0)\n",
    "    y_pred = model.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    return error\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(objective, n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1aced89-98ef-4629-84ba-3f9578c0b052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.8874193509552564\n",
      "Best Parameters: {'model__iterations': 955, 'model__max_depth': 6, 'model__subsample': 0.6382849390832925, 'model__learning_rate': 0.058582676139219296, 'model__min_child_samples': 38, 'model__l2_leaf_reg': 2}\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('RMSE: {}'.format(trial.value))\n",
    "print('Best Parameters: {}'.format(trial.params))\n",
    "# print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9180b18d-c166-44f1-ad07-f97a183de678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8874193509552564"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cat = CatBoostRegressor(verbose = 0, iterations = 955, max_depth = 6, subsample = 0.6382849390832925, \n",
    "                               learning_rate = 0.058582676139219296, min_child_samples = 38, l2_leaf_reg = 2) # Create the model\n",
    "model_cat.fit(X_train, y_train) # Train it (this syntax looks the same for all sklearn models)\n",
    "y_test_cat = model_cat.predict(X_test)\n",
    "error_test_cat = mean_squared_error(y_test, y_test_cat, squared = False)\n",
    "error_test_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b8b04-8fad-4291-baaf-0a85d27d1a93",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f66c77-ba3f-4daa-990b-ab38eb0eea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.160589080311209"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb_ = LGBMRegressor(verbose = 0) # Create the model\n",
    "model_lgb_.fit(X_train, y_train) # Train it (this syntax looks the same for all sklearn models)\n",
    "y_test_lgb = model_lgb_.predict(X_test)\n",
    "error_test_lgb = mean_squared_error(y_test, y_test_lgb, squared = False)\n",
    "error_test_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b187a1fa-ffea-46db-a6f6-7ac1281dfbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.78, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "RMSE LGBM: 3.0343555726957243\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.78, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "RMSE LGBM: 3.100009393817995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.78, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "RMSE LGBM: 3.2416362239049223\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.78, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "RMSE LGBM: 3.2006625076924626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.78, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "RMSE LGBM: 3.075678728688369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.075678728688369"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errlgb = []\n",
    "fold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in fold.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    param = {'objective': 'regression', \n",
    "         'metric': 'l2_root',\n",
    "         'learning_rate': 0.05, \n",
    "         'num_iterations': 2000,\n",
    "         'num_leaves': 35,\n",
    "         'max_depth': -1,\n",
    "         'min_data_in_leaf': 4,\n",
    "         'bagging_fraction': 0.78,\n",
    "         'bagging_freq': 1,\n",
    "         'feature_fraction': 0.65}\n",
    "    lgbm = LGBMRegressor(**param)\n",
    "    lgbm.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = 0, early_stopping_rounds=50)\n",
    "    y_pred_lgbm = lgbm.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred_lgbm, squared = False)\n",
    "    print(f\"RMSE LGBM: {error}\")\n",
    "errlgb.append(error)\n",
    "error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "feacb6cd-5b97-4a62-b076-50dfb9096af9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:38:48,769]\u001b[0m A new study created in memory with name: no-name-3087704c-60d6-4a4e-b9fe-83efaa7e2715\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:38:57,467]\u001b[0m Trial 0 finished with value: 3.1805386901437864 and parameters: {'learning_rate': 0.16358122243578527, 'subsample': 0.7306755229400822, 'n_estimators': 234, 'num_leaves': 31}. Best is trial 0 with value: 3.1805386901437864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:39:16,064]\u001b[0m Trial 1 finished with value: 3.487398009528127 and parameters: {'learning_rate': 0.3533731855152852, 'subsample': 0.9812062431930717, 'n_estimators': 224, 'num_leaves': 39}. Best is trial 0 with value: 3.1805386901437864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:39:35,838]\u001b[0m Trial 2 finished with value: 3.1223015476717437 and parameters: {'learning_rate': 0.13848917581203274, 'subsample': 0.7196563910174373, 'n_estimators': 354, 'num_leaves': 32}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:39:55,890]\u001b[0m Trial 3 finished with value: 3.1496734921882634 and parameters: {'learning_rate': 0.1157183167609413, 'subsample': 0.6521491278873952, 'n_estimators': 267, 'num_leaves': 36}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:40:21,589]\u001b[0m Trial 4 finished with value: 3.369554898480353 and parameters: {'learning_rate': 0.2796209878011162, 'subsample': 0.9335794889834536, 'n_estimators': 495, 'num_leaves': 38}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:40:54,820]\u001b[0m Trial 5 finished with value: 3.7755749057691426 and parameters: {'learning_rate': 0.48349558851384933, 'subsample': 0.7971294499405222, 'n_estimators': 181, 'num_leaves': 40}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:41:14,507]\u001b[0m Trial 6 finished with value: 3.798423960425463 and parameters: {'learning_rate': 0.48076953493037367, 'subsample': 0.7530700490327097, 'n_estimators': 349, 'num_leaves': 38}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:41:33,420]\u001b[0m Trial 7 finished with value: 3.562977498133527 and parameters: {'learning_rate': 0.390281211011121, 'subsample': 0.7702068858146398, 'n_estimators': 416, 'num_leaves': 34}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:41:48,753]\u001b[0m Trial 8 finished with value: 3.365674307074969 and parameters: {'learning_rate': 0.3186050775209758, 'subsample': 0.6473617898577023, 'n_estimators': 436, 'num_leaves': 34}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:42:01,689]\u001b[0m Trial 9 finished with value: 3.2702080128461306 and parameters: {'learning_rate': 0.31831673720008313, 'subsample': 0.7197049578428893, 'n_estimators': 197, 'num_leaves': 33}. Best is trial 2 with value: 3.1223015476717437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:42:13,391]\u001b[0m Trial 10 finished with value: 3.0318327146933104 and parameters: {'learning_rate': 0.04765149458318836, 'subsample': 0.8810388651875443, 'n_estimators': 128, 'num_leaves': 30}. Best is trial 10 with value: 3.0318327146933104.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:42:26,082]\u001b[0m Trial 11 finished with value: 3.0020065304389596 and parameters: {'learning_rate': 0.0335840589577861, 'subsample': 0.8692402551456782, 'n_estimators': 312, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:42:40,150]\u001b[0m Trial 12 finished with value: 3.019105913290788 and parameters: {'learning_rate': 0.035739995298034316, 'subsample': 0.877491553949462, 'n_estimators': 102, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:42:54,271]\u001b[0m Trial 13 finished with value: 3.148258474789926 and parameters: {'learning_rate': 0.07861277089211421, 'subsample': 0.8638369626527677, 'n_estimators': 123, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:43:07,241]\u001b[0m Trial 14 finished with value: 3.170173184978996 and parameters: {'learning_rate': 0.18860720396565145, 'subsample': 0.8573680703005175, 'n_estimators': 314, 'num_leaves': 32}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:43:19,974]\u001b[0m Trial 15 finished with value: 3.0364559121558674 and parameters: {'learning_rate': 0.04155656123797902, 'subsample': 0.9295814644691556, 'n_estimators': 293, 'num_leaves': 36}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:43:32,054]\u001b[0m Trial 16 finished with value: 3.1725992256484488 and parameters: {'learning_rate': 0.22235905379074927, 'subsample': 0.8332589273151784, 'n_estimators': 372, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:43:45,534]\u001b[0m Trial 17 finished with value: 3.0892750458993157 and parameters: {'learning_rate': 0.09681537374550868, 'subsample': 0.9215614702383894, 'n_estimators': 162, 'num_leaves': 32}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:43:55,261]\u001b[0m Trial 18 finished with value: 3.2128678384756832 and parameters: {'learning_rate': 0.19164066168226604, 'subsample': 0.9690576841767956, 'n_estimators': 263, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:44:08,035]\u001b[0m Trial 19 finished with value: 3.0528550441883704 and parameters: {'learning_rate': 0.042704215544244147, 'subsample': 0.8195958244853426, 'n_estimators': 399, 'num_leaves': 35}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:44:17,531]\u001b[0m Trial 20 finished with value: 3.2671356643002154 and parameters: {'learning_rate': 0.24609079781452092, 'subsample': 0.9031258570779325, 'n_estimators': 319, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:44:27,000]\u001b[0m Trial 21 finished with value: 3.0055406285325907 and parameters: {'learning_rate': 0.032613992475245615, 'subsample': 0.8828095117602918, 'n_estimators': 101, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:44:36,872]\u001b[0m Trial 22 finished with value: 3.1324931115128902 and parameters: {'learning_rate': 0.08894896290211823, 'subsample': 0.8969308467015252, 'n_estimators': 100, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:44:46,213]\u001b[0m Trial 23 finished with value: 3.0453998275175325 and parameters: {'learning_rate': 0.030947900340454745, 'subsample': 0.8458292325102181, 'n_estimators': 150, 'num_leaves': 33}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:44:55,083]\u001b[0m Trial 24 finished with value: 3.1143646705146786 and parameters: {'learning_rate': 0.13539488077721834, 'subsample': 0.8057349298088851, 'n_estimators': 195, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:45:07,197]\u001b[0m Trial 25 finished with value: 3.0737916076814535 and parameters: {'learning_rate': 0.07323173980544562, 'subsample': 0.9451397019557967, 'n_estimators': 118, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:45:21,178]\u001b[0m Trial 26 finished with value: 3.110826223903475 and parameters: {'learning_rate': 0.11509450565711202, 'subsample': 0.8767198078494282, 'n_estimators': 224, 'num_leaves': 33}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:45:29,602]\u001b[0m Trial 27 finished with value: 3.0916766097231174 and parameters: {'learning_rate': 0.07146930513747544, 'subsample': 0.7838772318971706, 'n_estimators': 153, 'num_leaves': 32}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:45:39,658]\u001b[0m Trial 28 finished with value: 3.1512670927392175 and parameters: {'learning_rate': 0.162326592287785, 'subsample': 0.9656895460685642, 'n_estimators': 284, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:45:49,274]\u001b[0m Trial 29 finished with value: 3.18040774197501 and parameters: {'learning_rate': 0.15606741349702505, 'subsample': 0.999042968536871, 'n_estimators': 232, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:45:58,429]\u001b[0m Trial 30 finished with value: 3.038349640954046 and parameters: {'learning_rate': 0.03185752913904235, 'subsample': 0.9045261104057665, 'n_estimators': 102, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:46:08,948]\u001b[0m Trial 31 finished with value: 3.0401927055016764 and parameters: {'learning_rate': 0.06952322978412762, 'subsample': 0.8765185654017253, 'n_estimators': 146, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:46:17,173]\u001b[0m Trial 32 finished with value: 3.04101070817167 and parameters: {'learning_rate': 0.05942283090965423, 'subsample': 0.8899983927060882, 'n_estimators': 139, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:46:25,850]\u001b[0m Trial 33 finished with value: 3.1294485233235694 and parameters: {'learning_rate': 0.1106582112812567, 'subsample': 0.834051383621458, 'n_estimators': 180, 'num_leaves': 32}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:46:35,176]\u001b[0m Trial 34 finished with value: 3.032837677780498 and parameters: {'learning_rate': 0.05586718679942208, 'subsample': 0.857852042015982, 'n_estimators': 125, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:46:45,983]\u001b[0m Trial 35 finished with value: 3.1254891739071597 and parameters: {'learning_rate': 0.12668847591679627, 'subsample': 0.9482582431919356, 'n_estimators': 249, 'num_leaves': 32}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:46:54,895]\u001b[0m Trial 36 finished with value: 3.1165435523114167 and parameters: {'learning_rate': 0.09723162507892119, 'subsample': 0.9167030422461955, 'n_estimators': 214, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:47:07,491]\u001b[0m Trial 37 finished with value: 3.2169681645945216 and parameters: {'learning_rate': 0.1862438718144676, 'subsample': 0.8179780872252677, 'n_estimators': 167, 'num_leaves': 37}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:47:18,630]\u001b[0m Trial 38 finished with value: 3.728772806753383 and parameters: {'learning_rate': 0.43003678435287696, 'subsample': 0.6864171667801793, 'n_estimators': 350, 'num_leaves': 40}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:47:27,306]\u001b[0m Trial 39 finished with value: 3.0574401484894342 and parameters: {'learning_rate': 0.05045774032270914, 'subsample': 0.6109518049798279, 'n_estimators': 323, 'num_leaves': 34}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:47:37,209]\u001b[0m Trial 40 finished with value: 3.1427695454576248 and parameters: {'learning_rate': 0.14643996843696316, 'subsample': 0.7622617999216152, 'n_estimators': 101, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:47:45,913]\u001b[0m Trial 41 finished with value: 3.064239374067 and parameters: {'learning_rate': 0.06023686218667573, 'subsample': 0.8734686959713708, 'n_estimators': 131, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:47:53,951]\u001b[0m Trial 42 finished with value: 3.027973495596776 and parameters: {'learning_rate': 0.03247336688607365, 'subsample': 0.8494997708959625, 'n_estimators': 117, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:48:03,438]\u001b[0m Trial 43 finished with value: 3.02000498875814 and parameters: {'learning_rate': 0.03194989951715052, 'subsample': 0.8423642902217576, 'n_estimators': 466, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:48:13,251]\u001b[0m Trial 44 finished with value: 3.0622770057854187 and parameters: {'learning_rate': 0.09066588785390153, 'subsample': 0.8416690418012371, 'n_estimators': 493, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:48:21,610]\u001b[0m Trial 45 finished with value: 3.0479845022081826 and parameters: {'learning_rate': 0.035054768093662536, 'subsample': 0.7907529497406515, 'n_estimators': 441, 'num_leaves': 31}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:48:31,092]\u001b[0m Trial 46 finished with value: 3.131851947509445 and parameters: {'learning_rate': 0.10814535324883115, 'subsample': 0.8185982147427958, 'n_estimators': 469, 'num_leaves': 33}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:48:40,652]\u001b[0m Trial 47 finished with value: 3.351390578065139 and parameters: {'learning_rate': 0.31724392502949084, 'subsample': 0.8582299262788565, 'n_estimators': 376, 'num_leaves': 30}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:49:04,438]\u001b[0m Trial 48 finished with value: 3.026125562101571 and parameters: {'learning_rate': 0.030317840354062136, 'subsample': 0.7471385611779329, 'n_estimators': 418, 'num_leaves': 39}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:49:19,567]\u001b[0m Trial 49 finished with value: 3.1019508528300883 and parameters: {'learning_rate': 0.08392888950960342, 'subsample': 0.7366263057709261, 'n_estimators': 454, 'num_leaves': 39}. Best is trial 11 with value: 3.0020065304389596.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    model = LGBMRegressor(\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.03, 0.5),\n",
    "        subsample = trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        n_estimators = trial.suggest_int('n_estimators', 100, 500),\n",
    "        num_leaves = trial.suggest_int('num_leaves', 30, 40),\n",
    "        objective = 'regression', \n",
    "        metric = 'l2_root',\n",
    "        num_iterations = 2000,\n",
    "        max_depth = -1,\n",
    "        feature_fraction = 0.65,\n",
    "        verbose = 0)\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose = 0)\n",
    "    y_pred = model.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    return error\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(objective, n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9664a845-23e0-48bd-9a62-9ccf36b3b26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.0020065304389596\n",
      "Best Parameters: {'learning_rate': 0.0335840589577861, 'subsample': 0.8692402551456782, 'n_estimators': 312, 'num_leaves': 30}\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('RMSE: {}'.format(trial.value))\n",
    "print('Best Parameters: {}'.format(trial.params))\n",
    "# print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51d48eed-4d61-46b7-8610-10493e8b998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.78, subsample=0.9092367008636046 will be ignored. Current value: bagging_fraction=0.78\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.78, subsample=0.9092367008636046 will be ignored. Current value: bagging_fraction=0.78\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.982444358919984"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'objective': 'regression', \n",
    "         'metric': 'l2_root',\n",
    "         'learning_rate': 0.032314807938206576,\n",
    "         'subsample' : 0.9092367008636046,\n",
    "         'num_iterations': 2000,\n",
    "         'num_leaves': 36,\n",
    "         'n_estimators' : 492,\n",
    "         'max_depth': -1,\n",
    "         'min_data_in_leaf': 4,\n",
    "         'bagging_fraction': 0.78,\n",
    "         'bagging_freq': 1,\n",
    "         'feature_fraction': 0.65,\n",
    "         'verbose' : 0}\n",
    "model_lgb = LGBMRegressor(**param) # Create the model\n",
    "model_lgb.fit(X_train, y_train) # Train it (this syntax looks the same for all sklearn models)\n",
    "y_test_lgb = model_lgb.predict(X_test)\n",
    "error_test_lgb = mean_squared_error(y_test, y_test_lgb, squared = False)\n",
    "error_test_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa82b9-eeee-4fb6-8fbc-1f1ca55c49b9",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2abd5d13-9d43-4b76-b2d3-476c1ef54c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3804380442948894"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(verbose = 0) # Create the model\n",
    "model_xgb.fit(X_train, y_train) # Train it (this syntax looks the same for all sklearn models)\n",
    "y_test_xgb = model_xgb.predict(X_test)\n",
    "error_test_xgb = mean_squared_error(y_test, y_test_xgb, squared = False)\n",
    "error_test_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c190c02-3ebc-4f03-8881-745bb8690e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE LGBM: 3.374716286406206\n",
      "RMSE LGBM: 3.6055284090777873\n",
      "RMSE LGBM: 3.451197287238\n",
      "RMSE LGBM: 3.490860925072187\n",
      "RMSE LGBM: 3.4824971141632948\n",
      "CV_RMSE: 3.4134131251076405\n"
     ]
    }
   ],
   "source": [
    "errxgb = []\n",
    "fold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in fold.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model_xgb = XGBRegressor() # Create the model\n",
    "    model_xgb.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = 0, early_stopping_rounds=50) # Train it (this syntax looks the same for all sklearn models)\n",
    "    y_hat = model_xgb.predict(X_test)\n",
    "    error_test = mean_squared_error(y_test, y_hat, squared = False)\n",
    "    errxgb.append(error_test)\n",
    "    print(f\"RMSE LGBM: {error_test}\")\n",
    "errxgb.append(error)\n",
    "print(f'CV_RMSE: {np.mean(errxgb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74e0761c-3923-4299-a94b-6ed3721f38bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:16:42,628]\u001b[0m A new study created in memory with name: no-name-bfdf503a-615b-45ca-8f12-767106c63a3c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:23.54061\n",
      "[387]\tvalidation_0-rmse:3.29474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:16:46,846]\u001b[0m Trial 0 finished with value: 3.27225797683086 and parameters: {'learning_rate': 0.09528814491404994, 'reg_lambda': 3.6031892433748592e-06, 'reg_alpha': 0.35397151898627405, 'subsample': 0.31022823412861833, 'colsample_bylevel': 0.9148542977342179, 'colsample_bytree': 0.5143269313437568, 'max_depth': 9}. Best is trial 0 with value: 3.27225797683086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.42235\n",
      "[1000]\tvalidation_0-rmse:3.17885\n",
      "[1999]\tvalidation_0-rmse:3.17785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:17:05,056]\u001b[0m Trial 1 finished with value: 3.177852016270951 and parameters: {'learning_rate': 0.021411920246858885, 'reg_lambda': 0.044939223887503536, 'reg_alpha': 2.6592228830276747e-08, 'subsample': 0.935392688595594, 'colsample_bylevel': 0.3374677348384588, 'colsample_bytree': 0.32475369175023705, 'max_depth': 8}. Best is trial 1 with value: 3.177852016270951.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:22.90615\n",
      "[790]\tvalidation_0-rmse:3.10527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:17:12,856]\u001b[0m Trial 2 finished with value: 3.1029661051326327 and parameters: {'learning_rate': 0.12015635469976012, 'reg_lambda': 2.663440229770677e-06, 'reg_alpha': 0.0023169577444464374, 'subsample': 0.6745945455779123, 'colsample_bylevel': 0.4427613787098126, 'colsample_bytree': 0.8706470615859915, 'max_depth': 5}. Best is trial 2 with value: 3.1029661051326327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.27284\n",
      "[1000]\tvalidation_0-rmse:3.05781\n",
      "[1352]\tvalidation_0-rmse:3.05795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:17:32,697]\u001b[0m Trial 3 finished with value: 3.0569695991794887 and parameters: {'learning_rate': 0.027044157806983916, 'reg_lambda': 1.756418088529679e-06, 'reg_alpha': 2.704252856285567e-07, 'subsample': 0.3881990896890719, 'colsample_bylevel': 0.8312700894652364, 'colsample_bytree': 0.9106855553803007, 'max_depth': 7}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:20.96962\n",
      "[361]\tvalidation_0-rmse:3.43217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:17:35,391]\u001b[0m Trial 4 finished with value: 3.409836622834997 and parameters: {'learning_rate': 0.19933766158614533, 'reg_lambda': 4.042218481321995e-08, 'reg_alpha': 7.273915311617636, 'subsample': 0.45576699039596436, 'colsample_bylevel': 0.6862489665137957, 'colsample_bytree': 0.8692256460279563, 'max_depth': 3}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:20.28060\n",
      "[589]\tvalidation_0-rmse:3.29805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:17:41,021]\u001b[0m Trial 5 finished with value: 3.296230981480334 and parameters: {'learning_rate': 0.22379207605245016, 'reg_lambda': 3.252069299675288e-08, 'reg_alpha': 0.00024202347382126004, 'subsample': 0.5592344175235627, 'colsample_bylevel': 0.6198764696465193, 'colsample_bytree': 0.7361258962781192, 'max_depth': 5}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.43217\n",
      "[1000]\tvalidation_0-rmse:3.16215\n",
      "[1999]\tvalidation_0-rmse:3.15394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:18:11,062]\u001b[0m Trial 6 finished with value: 3.1539422190415185 and parameters: {'learning_rate': 0.021536162558915026, 'reg_lambda': 7.092909839701684, 'reg_alpha': 3.4444432529637274e-08, 'subsample': 0.644335918538765, 'colsample_bylevel': 0.5095167309219991, 'colsample_bytree': 0.5389707690896899, 'max_depth': 10}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:23.29568\n",
      "[363]\tvalidation_0-rmse:3.73721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:18:13,308]\u001b[0m Trial 7 finished with value: 3.696988876413855 and parameters: {'learning_rate': 0.10427694689320999, 'reg_lambda': 2.4285795522706712e-05, 'reg_alpha': 1.4426182783447725e-06, 'subsample': 0.18482671471501844, 'colsample_bylevel': 0.21867093708076074, 'colsample_bytree': 0.5695568304341581, 'max_depth': 7}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:22.06589\n",
      "[462]\tvalidation_0-rmse:3.25468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:18:22,470]\u001b[0m Trial 8 finished with value: 3.2546298279007035 and parameters: {'learning_rate': 0.1529142838985035, 'reg_lambda': 7.683833832710811e-08, 'reg_alpha': 1.2827660059284335e-07, 'subsample': 0.9568286484241931, 'colsample_bylevel': 0.990603269964496, 'colsample_bytree': 0.6967449155735033, 'max_depth': 9}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.49239\n",
      "[1000]\tvalidation_0-rmse:3.08485\n",
      "[1062]\tvalidation_0-rmse:3.09245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:18:32,220]\u001b[0m Trial 9 finished with value: 3.0795831629110597 and parameters: {'learning_rate': 0.05798114816457437, 'reg_lambda': 6.387044431011859e-07, 'reg_alpha': 4.362781458270658e-05, 'subsample': 0.629045317266124, 'colsample_bylevel': 0.4338477845913319, 'colsample_bytree': 0.6190007749280073, 'max_depth': 4}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.67918\n",
      "[1000]\tvalidation_0-rmse:3.10515\n",
      "[1307]\tvalidation_0-rmse:3.11066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:18:44,465]\u001b[0m Trial 10 finished with value: 3.1011831714989144 and parameters: {'learning_rate': 0.011310187637355662, 'reg_lambda': 0.0018355004703196644, 'reg_alpha': 0.018591261498383287, 'subsample': 0.1255942981831022, 'colsample_bylevel': 0.7957619855940321, 'colsample_bytree': 0.9908483504372441, 'max_depth': 6}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.91653\n",
      "[1000]\tvalidation_0-rmse:3.48151\n",
      "[1999]\tvalidation_0-rmse:3.37953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:18:53,162]\u001b[0m Trial 11 finished with value: 3.3780842055210463 and parameters: {'learning_rate': 0.044651499422352484, 'reg_lambda': 0.00024822796524316524, 'reg_alpha': 1.3836500219540466e-05, 'subsample': 0.4570411311907123, 'colsample_bylevel': 0.1465143344477413, 'colsample_bytree': 0.14114427502720361, 'max_depth': 3}. Best is trial 3 with value: 3.0569695991794887.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.95467\n",
      "[1000]\tvalidation_0-rmse:3.05333\n",
      "[1699]\tvalidation_0-rmse:3.04905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:19:10,574]\u001b[0m Trial 12 finished with value: 3.047513311129136 and parameters: {'learning_rate': 0.03970424383870451, 'reg_lambda': 6.539023410389342e-07, 'reg_alpha': 1.8901039725909097e-05, 'subsample': 0.7817433293183029, 'colsample_bylevel': 0.7393611445502098, 'colsample_bytree': 0.3780323694517256, 'max_depth': 5}. Best is trial 12 with value: 3.047513311129136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:19:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.08879\n",
      "[1000]\tvalidation_0-rmse:3.03905\n",
      "[1999]\tvalidation_0-rmse:3.03853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:19:35,604]\u001b[0m Trial 13 finished with value: 3.0385085159076275 and parameters: {'learning_rate': 0.034096377822190674, 'reg_lambda': 0.0001223369009564926, 'reg_alpha': 1.8953545019168038e-06, 'subsample': 0.8267098290678822, 'colsample_bylevel': 0.778326533577048, 'colsample_bytree': 0.3550627022664885, 'max_depth': 7}. Best is trial 13 with value: 3.0385085159076275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:19:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.85145\n",
      "[1000]\tvalidation_0-rmse:2.98377\n",
      "[1293]\tvalidation_0-rmse:2.98427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:19:49,200]\u001b[0m Trial 14 finished with value: 2.9836194694839633 and parameters: {'learning_rate': 0.04391544460330591, 'reg_lambda': 0.013190293231373705, 'reg_alpha': 4.3089716227862265e-06, 'subsample': 0.8024940652227448, 'colsample_bylevel': 0.7678857413280744, 'colsample_bytree': 0.34628687886157344, 'max_depth': 6}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:19:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.25983\n",
      "[1000]\tvalidation_0-rmse:3.10400\n",
      "[1142]\tvalidation_0-rmse:3.10415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:19:58,108]\u001b[0m Trial 15 finished with value: 3.1031967616666662 and parameters: {'learning_rate': 0.0689784801542699, 'reg_lambda': 0.11180750125339418, 'reg_alpha': 1.9287382985002768e-06, 'subsample': 0.8176715906333063, 'colsample_bylevel': 0.5852870089216318, 'colsample_bytree': 0.2262047095689747, 'max_depth': 6}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:19:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.15585\n",
      "[1000]\tvalidation_0-rmse:3.09409\n",
      "[1144]\tvalidation_0-rmse:3.09404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:20:18,467]\u001b[0m Trial 16 finished with value: 3.093976942359861 and parameters: {'learning_rate': 0.03169933507294892, 'reg_lambda': 0.005735372312317361, 'reg_alpha': 0.0025119952136818183, 'subsample': 0.8131078764691174, 'colsample_bylevel': 0.8621751471471251, 'colsample_bytree': 0.3869655100029767, 'max_depth': 8}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.62839\n",
      "[1000]\tvalidation_0-rmse:3.13115\n",
      "[1999]\tvalidation_0-rmse:3.09169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:20:38,797]\u001b[0m Trial 17 finished with value: 3.0916939126290144 and parameters: {'learning_rate': 0.014109813024321533, 'reg_lambda': 9.925568908746506, 'reg_alpha': 2.182432403446688e-06, 'subsample': 0.7502960279134352, 'colsample_bylevel': 0.6860265656511103, 'colsample_bytree': 0.24143045507960734, 'max_depth': 7}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.18782\n",
      "[1000]\tvalidation_0-rmse:3.42389\n",
      "[1535]\tvalidation_0-rmse:3.42388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:20:50,313]\u001b[0m Trial 18 finished with value: 3.4238821177527083 and parameters: {'learning_rate': 0.07195004270562036, 'reg_lambda': 0.00012808193592385344, 'reg_alpha': 0.00010341975225459203, 'subsample': 0.8980947831236861, 'colsample_bylevel': 0.9954934983215908, 'colsample_bytree': 0.10755983927070334, 'max_depth': 8}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.11733\n",
      "[1000]\tvalidation_0-rmse:3.01695\n",
      "[1999]\tvalidation_0-rmse:3.01563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:21:20,355]\u001b[0m Trial 19 finished with value: 3.015465471744035 and parameters: {'learning_rate': 0.033587411615402386, 'reg_lambda': 0.39283079491156836, 'reg_alpha': 0.023198580392311745, 'subsample': 0.9896818815883269, 'colsample_bylevel': 0.7411283733270573, 'colsample_bytree': 0.45011159500914144, 'max_depth': 6}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:21:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.50650\n",
      "[1000]\tvalidation_0-rmse:3.03370\n",
      "[1999]\tvalidation_0-rmse:2.98925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:21:41,704]\u001b[0m Trial 20 finished with value: 2.9892423436520725 and parameters: {'learning_rate': 0.01818644227420227, 'reg_lambda': 0.556572047212965, 'reg_alpha': 0.06969830814030903, 'subsample': 0.9694218105218002, 'colsample_bylevel': 0.6589024212462895, 'colsample_bytree': 0.4719741991057175, 'max_depth': 4}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.38588\n",
      "[1000]\tvalidation_0-rmse:3.05078\n",
      "[1999]\tvalidation_0-rmse:3.01348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:22:00,813]\u001b[0m Trial 21 finished with value: 3.013476533733746 and parameters: {'learning_rate': 0.022794863912916085, 'reg_lambda': 0.5819897311534736, 'reg_alpha': 0.12383973736818896, 'subsample': 0.9678690280376635, 'colsample_bylevel': 0.6479425224024286, 'colsample_bytree': 0.4353834787399109, 'max_depth': 4}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.51711\n",
      "[1000]\tvalidation_0-rmse:3.03806\n",
      "[1999]\tvalidation_0-rmse:2.99458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:22:22,885]\u001b[0m Trial 22 finished with value: 2.993194056224696 and parameters: {'learning_rate': 0.01775416257304691, 'reg_lambda': 1.551021632895613, 'reg_alpha': 1.0669868963332771, 'subsample': 0.8842152857491917, 'colsample_bylevel': 0.6399243078942883, 'colsample_bytree': 0.4588961650483562, 'max_depth': 4}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.53374\n",
      "[1000]\tvalidation_0-rmse:3.20302\n",
      "[1999]\tvalidation_0-rmse:3.13314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:22:37,289]\u001b[0m Trial 23 finished with value: 3.133089473413998 and parameters: {'learning_rate': 0.017594901767077845, 'reg_lambda': 1.4951610967716142, 'reg_alpha': 52.734791647763636, 'subsample': 0.8756211979617815, 'colsample_bylevel': 0.5754144841947473, 'colsample_bytree': 0.2522038935379, 'max_depth': 4}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.73725\n",
      "[1000]\tvalidation_0-rmse:3.40952\n",
      "[1999]\tvalidation_0-rmse:3.24407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:22:54,070]\u001b[0m Trial 24 finished with value: 3.2440729028602324 and parameters: {'learning_rate': 0.01018915248852883, 'reg_lambda': 81.65081027002073, 'reg_alpha': 1.6882210504191417, 'subsample': 0.7269359227216254, 'colsample_bylevel': 0.5130036304246945, 'colsample_bytree': 0.46524624721702457, 'max_depth': 3}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.62382\n",
      "[1000]\tvalidation_0-rmse:3.23805\n",
      "[1999]\tvalidation_0-rmse:3.17178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:23:27,362]\u001b[0m Trial 25 finished with value: 3.171783836917081 and parameters: {'learning_rate': 0.013753250060153663, 'reg_lambda': 0.015486276719703936, 'reg_alpha': 87.28882554481386, 'subsample': 0.879817601876974, 'colsample_bylevel': 0.8972952480243955, 'colsample_bytree': 0.6258457163974733, 'max_depth': 4}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.61254\n",
      "[1000]\tvalidation_0-rmse:3.26352\n",
      "[1999]\tvalidation_0-rmse:3.16933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:23:50,012]\u001b[0m Trial 26 finished with value: 3.169328039142068 and parameters: {'learning_rate': 0.015790824571726522, 'reg_lambda': 86.16479719982982, 'reg_alpha': 0.036867896633573996, 'subsample': 0.7195481700249853, 'colsample_bylevel': 0.686390835806528, 'colsample_bytree': 0.279746043176491, 'max_depth': 5}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.62253\n",
      "[1000]\tvalidation_0-rmse:3.08463\n",
      "[1688]\tvalidation_0-rmse:3.07979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:24:09,910]\u001b[0m Trial 27 finished with value: 3.076788502372195 and parameters: {'learning_rate': 0.05462506888841066, 'reg_lambda': 5.7750817206856135, 'reg_alpha': 2.5842542610199994, 'subsample': 0.9945619803453756, 'colsample_bylevel': 0.4635014413518285, 'colsample_bytree': 0.4833287624396101, 'max_depth': 4}. Best is trial 14 with value: 2.9836194694839633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:24:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.30334\n",
      "[1000]\tvalidation_0-rmse:2.97588\n",
      "[1888]\tvalidation_0-rmse:2.96546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:24:32,644]\u001b[0m Trial 28 finished with value: 2.9645893926554514 and parameters: {'learning_rate': 0.026435134382193665, 'reg_lambda': 0.09299511271948924, 'reg_alpha': 0.0006909111530222147, 'subsample': 0.8621947098581921, 'colsample_bylevel': 0.3057862926734608, 'colsample_bytree': 0.7215302502189153, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:24:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.28849\n",
      "[1000]\tvalidation_0-rmse:3.00301\n",
      "[1873]\tvalidation_0-rmse:2.99501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:24:58,650]\u001b[0m Trial 29 finished with value: 2.994249028492119 and parameters: {'learning_rate': 0.026927781966881434, 'reg_lambda': 0.057448525881538044, 'reg_alpha': 0.0005160051946401365, 'subsample': 0.6101586786427762, 'colsample_bylevel': 0.3272716421942421, 'colsample_bytree': 0.7183740715898259, 'max_depth': 6}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:24:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.94205\n",
      "[1000]\tvalidation_0-rmse:3.00839\n",
      "[1770]\tvalidation_0-rmse:3.00232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:25:17,509]\u001b[0m Trial 30 finished with value: 3.001784480279257 and parameters: {'learning_rate': 0.04062043725901252, 'reg_lambda': 0.012630859803247126, 'reg_alpha': 0.005772694407878984, 'subsample': 0.8495783531185214, 'colsample_bylevel': 0.3293076316836221, 'colsample_bytree': 0.6549003357254168, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:25:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.50462\n",
      "[1000]\tvalidation_0-rmse:2.99473\n",
      "[1999]\tvalidation_0-rmse:2.97797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:25:46,631]\u001b[0m Trial 31 finished with value: 2.9778667868691113 and parameters: {'learning_rate': 0.01831089101294394, 'reg_lambda': 0.23583375896037356, 'reg_alpha': 0.2494226559738959, 'subsample': 0.9151535236203875, 'colsample_bylevel': 0.6156833864342884, 'colsample_bytree': 0.7802831709718365, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:25:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.31739\n",
      "[1000]\tvalidation_0-rmse:2.98939\n",
      "[1999]\tvalidation_0-rmse:2.97297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:26:11,972]\u001b[0m Trial 32 finished with value: 2.9725908979946225 and parameters: {'learning_rate': 0.025205108270213356, 'reg_lambda': 0.15935003165524447, 'reg_alpha': 0.27524647488011056, 'subsample': 0.9267826059186375, 'colsample_bylevel': 0.24572417751598097, 'colsample_bytree': 0.7411149453054939, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.30878\n",
      "[1000]\tvalidation_0-rmse:2.99081\n",
      "[1999]\tvalidation_0-rmse:2.98764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:26:41,244]\u001b[0m Trial 33 finished with value: 2.987412547911115 and parameters: {'learning_rate': 0.025952077780922247, 'reg_lambda': 0.002093702297458393, 'reg_alpha': 0.3842346351030496, 'subsample': 0.9121242297733619, 'colsample_bylevel': 0.2427406757010745, 'colsample_bytree': 0.8054529453256123, 'max_depth': 6}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.37641\n",
      "[1000]\tvalidation_0-rmse:3.05704\n",
      "[1999]\tvalidation_0-rmse:3.03704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:26:58,599]\u001b[0m Trial 34 finished with value: 3.036875743437359 and parameters: {'learning_rate': 0.023383595400936482, 'reg_lambda': 0.1343920689241797, 'reg_alpha': 17.594045013844198, 'subsample': 0.7834721162396923, 'colsample_bylevel': 0.12374937321701049, 'colsample_bytree': 0.766888609583452, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.19079\n",
      "[1000]\tvalidation_0-rmse:3.00194\n",
      "[1653]\tvalidation_0-rmse:2.99647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:27:26,589]\u001b[0m Trial 35 finished with value: 2.996003496902358 and parameters: {'learning_rate': 0.031022040008509937, 'reg_lambda': 0.018377557897401465, 'reg_alpha': 0.33623381262823393, 'subsample': 0.7043210871289294, 'colsample_bylevel': 0.3875673438818835, 'colsample_bytree': 0.828499696225458, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:27:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.76382\n",
      "[1000]\tvalidation_0-rmse:3.07484\n",
      "[1013]\tvalidation_0-rmse:3.07471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:27:45,295]\u001b[0m Trial 36 finished with value: 3.0731401293079323 and parameters: {'learning_rate': 0.04741132868203743, 'reg_lambda': 0.0005176166049542398, 'reg_alpha': 0.26030888356536047, 'subsample': 0.9161662241279981, 'colsample_bylevel': 0.23319768235281546, 'colsample_bytree': 0.9387708094857238, 'max_depth': 6}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:27:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.46439\n",
      "[1000]\tvalidation_0-rmse:3.03497\n",
      "[1999]\tvalidation_0-rmse:2.99791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:28:12,664]\u001b[0m Trial 37 finished with value: 2.9977234854296193 and parameters: {'learning_rate': 0.019666432570667167, 'reg_lambda': 0.06091705697451666, 'reg_alpha': 0.005317321941996312, 'subsample': 0.31478979669748763, 'colsample_bylevel': 0.2860791612644829, 'colsample_bytree': 0.8013054197941105, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.18147\n",
      "[890]\tvalidation_0-rmse:3.07379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:28:21,132]\u001b[0m Trial 38 finished with value: 3.0690252936793834 and parameters: {'learning_rate': 0.07055083897273284, 'reg_lambda': 0.007184779679573193, 'reg_alpha': 0.0003992863822866001, 'subsample': 0.5527620314334912, 'colsample_bylevel': 0.16106233211153922, 'colsample_bytree': 0.8837296660080624, 'max_depth': 5}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:24.98498\n",
      "[1000]\tvalidation_0-rmse:3.02573\n",
      "[1184]\tvalidation_0-rmse:3.02603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:28:39,254]\u001b[0m Trial 39 finished with value: 3.0245468551527015 and parameters: {'learning_rate': 0.038573911822563714, 'reg_lambda': 0.26109835466770226, 'reg_alpha': 1.5660669570537988e-08, 'subsample': 0.7685853546123781, 'colsample_bylevel': 0.38991977483718226, 'colsample_bytree': 0.5942663837167557, 'max_depth': 6}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:28:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.27023\n",
      "[1000]\tvalidation_0-rmse:3.07634\n",
      "[1159]\tvalidation_0-rmse:3.07586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:28:54,147]\u001b[0m Trial 40 finished with value: 3.075730485399354 and parameters: {'learning_rate': 0.028008650710955277, 'reg_lambda': 2.529898278753345, 'reg_alpha': 0.0011702293208077398, 'subsample': 0.6782349650572307, 'colsample_bylevel': 0.19303628101940035, 'colsample_bytree': 0.6762771435544915, 'max_depth': 8}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.31427\n",
      "[1000]\tvalidation_0-rmse:2.96828\n",
      "[1785]\tvalidation_0-rmse:2.96570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:29:18,469]\u001b[0m Trial 41 finished with value: 2.9655136920993153 and parameters: {'learning_rate': 0.025433766123262876, 'reg_lambda': 0.002310674644083045, 'reg_alpha': 0.6418903195206982, 'subsample': 0.9119252407462796, 'colsample_bylevel': 0.2665853314527779, 'colsample_bytree': 0.7716193640959264, 'max_depth': 6}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.40967\n",
      "[1000]\tvalidation_0-rmse:3.03332\n",
      "[1828]\tvalidation_0-rmse:3.03106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:29:48,392]\u001b[0m Trial 42 finished with value: 3.0304566370008756 and parameters: {'learning_rate': 0.021595534647415517, 'reg_lambda': 0.03491534722671933, 'reg_alpha': 4.688574139993225, 'subsample': 0.9488907512204663, 'colsample_bylevel': 0.2726713963445353, 'colsample_bytree': 0.741265369269439, 'max_depth': 7}. Best is trial 28 with value: 2.9645893926554514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.62276\n",
      "[1000]\tvalidation_0-rmse:2.99545\n",
      "[1999]\tvalidation_0-rmse:2.94815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:30:22,431]\u001b[0m Trial 43 finished with value: 2.947958452285846 and parameters: {'learning_rate': 0.013405751761321347, 'reg_lambda': 1.912400936649247e-05, 'reg_alpha': 3.007881279310061e-07, 'subsample': 0.8418942683145513, 'colsample_bylevel': 0.3756176572022918, 'colsample_bytree': 0.8408725111250259, 'max_depth': 5}. Best is trial 43 with value: 2.947958452285846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.67656\n",
      "[1000]\tvalidation_0-rmse:3.01890\n",
      "[1999]\tvalidation_0-rmse:2.96784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:30:52,408]\u001b[0m Trial 44 finished with value: 2.9677635614682574 and parameters: {'learning_rate': 0.011288759204195045, 'reg_lambda': 1.3154602122531652e-05, 'reg_alpha': 1.1819869154003413e-07, 'subsample': 0.8461939348160745, 'colsample_bylevel': 0.35867493798910416, 'colsample_bytree': 0.8388894442791196, 'max_depth': 5}. Best is trial 43 with value: 2.947958452285846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.67631\n",
      "[1000]\tvalidation_0-rmse:3.01689\n",
      "[1999]\tvalidation_0-rmse:2.96089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:31:33,835]\u001b[0m Trial 45 finished with value: 2.9608163670255965 and parameters: {'learning_rate': 0.011272118748764657, 'reg_lambda': 2.3509669088243254e-05, 'reg_alpha': 1.901966884187689e-07, 'subsample': 0.8536155576953119, 'colsample_bylevel': 0.37604970656841946, 'colsample_bytree': 0.8483890504099612, 'max_depth': 5}. Best is trial 43 with value: 2.947958452285846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:31:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.64484\n",
      "[1000]\tvalidation_0-rmse:3.11497\n",
      "[1999]\tvalidation_0-rmse:3.11446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:32:38,205]\u001b[0m Trial 46 finished with value: 3.1144582359372293 and parameters: {'learning_rate': 0.012496494172808929, 'reg_lambda': 1.2373477722194043e-05, 'reg_alpha': 3.6373306335381406e-07, 'subsample': 0.8426517040745691, 'colsample_bylevel': 0.3814915375630571, 'colsample_bytree': 0.9554778547760626, 'max_depth': 10}. Best is trial 43 with value: 2.947958452285846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:32:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.70006\n",
      "[1000]\tvalidation_0-rmse:3.03638\n",
      "[1999]\tvalidation_0-rmse:2.97663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:33:03,655]\u001b[0m Trial 47 finished with value: 2.9757104828479686 and parameters: {'learning_rate': 0.01034881315666673, 'reg_lambda': 1.7539863778746273e-05, 'reg_alpha': 7.875565079894343e-08, 'subsample': 0.4953835201159814, 'colsample_bylevel': 0.453666791043669, 'colsample_bytree': 0.8326064914150392, 'max_depth': 5}. Best is trial 43 with value: 2.947958452285846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.65905\n",
      "[1000]\tvalidation_0-rmse:2.98365\n",
      "[1999]\tvalidation_0-rmse:2.97047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:33:32,292]\u001b[0m Trial 48 finished with value: 2.9704371909906895 and parameters: {'learning_rate': 0.012137853742959247, 'reg_lambda': 4.846703733926485e-06, 'reg_alpha': 3.669245792042979e-07, 'subsample': 0.8401046927142767, 'colsample_bylevel': 0.2869110507676956, 'colsample_bytree': 0.868570643752211, 'max_depth': 7}. Best is trial 43 with value: 2.947958452285846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:33:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[0]\tvalidation_0-rmse:25.58576\n",
      "[1000]\tvalidation_0-rmse:3.13122\n",
      "[1999]\tvalidation_0-rmse:3.03540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-19 21:33:51,264]\u001b[0m Trial 49 finished with value: 3.0341416645312314 and parameters: {'learning_rate': 0.015186407636673272, 'reg_lambda': 7.543018473740945e-07, 'reg_alpha': 5.533422807850566e-08, 'subsample': 0.7605508883137756, 'colsample_bylevel': 0.3653376325526461, 'colsample_bytree': 0.9014287937655918, 'max_depth': 3}. Best is trial 43 with value: 2.947958452285846.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def run(trial):\n",
    "    model = XGBRegressor(\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-2, 0.25, log = True),\n",
    "        reg_lambda = trial.suggest_loguniform('reg_lambda', 1e-8, 100.0),\n",
    "        reg_alpha = trial.suggest_loguniform('reg_alpha', 1e-8, 100.0),\n",
    "        subsample = trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 10),\n",
    "        gpu_id = 1,\n",
    "        n_estimators = 2000)\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose = 1000, early_stopping_rounds = 300, eval_set = [(X_test, y_test)])\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(run, n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96269785-c9a7-4c8a-8a30-1f2483680492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.947958452285846\n",
      "Best Parameters: {'learning_rate': 0.013405751761321347, 'reg_lambda': 1.912400936649247e-05, 'reg_alpha': 3.007881279310061e-07, 'subsample': 0.8418942683145513, 'colsample_bylevel': 0.3756176572022918, 'colsample_bytree': 0.8408725111250259, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('RMSE: {}'.format(trial.value))\n",
    "print('Best Parameters: {}'.format(trial.params))\n",
    "# print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "242c8e7b-7c77-45ca-9ab1-39f6fc9d3f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:38:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.846033245739254"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params: {'learning_rate': 0.013405751761321347,\n",
    "         'reg_lambda': 1.912400936649247e-05,\n",
    "         'reg_alpha': 3.007881279310061e-07, \n",
    "         'subsample': 0.8418942683145513, \n",
    "         'colsample_bylevel': 0.3756176572022918, \n",
    "         'colsample_bytree': 8408725111250259, \n",
    "         'max_depth': 5,\n",
    "         'gpu_id' : 1,\n",
    "         'n_estimators' : 2000}\n",
    "model_xgb = XGBRegressor(**params) # Create the model\n",
    "model_xgb.fit(X_train, y_train) # Train it (this syntax looks the same for all sklearn models)\n",
    "y_hat_xgb = model_xgb.predict(X_test)\n",
    "error_xgb = mean_squared_error(y_test, y_hat_xgb, squared = False)\n",
    "error_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53acad1d-c983-431e-8e56-9ef305abe053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test__ = test[main]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5262bd1f-a066-4fde-aa03-422c5a7bda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cat.predict(X_test__).round(6)\n",
    "b = model_cat_.predict(X_test__).round(6)\n",
    "c = model_lgb_.predict(X_test__).round(6)\n",
    "d = lgbm.predict(X_test__).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa70ae89-fdda-4a6e-ace3-981794a22742",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_1 = (a + b + c + d) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e358913-46e7-4be3-aedd-1d8d3501c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_2 = a*0.15 + b*0.4 + c*0.3 + d*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23a0e97f-d97f-4a74-98f1-5304002c22be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss.target = test_pred_1\n",
    "ss.to_csv('model_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2a68f1a-812b-44ff-b8a2-348864ebabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.target = test_pred_2\n",
    "ss.to_csv('model_11.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
